{
  "last_node_id": 22,
  "last_link_id": 39,
  "nodes": [
    {
      "id": 4,
      "type": "CLIPVisionLoader",
      "pos": [
        526.2491785312387,
        393.30889814274616
      ],
      "size": {
        "0": 300,
        "1": 60
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            2
          ],
          "shape": 3,
          "slot_index": 0,
          "label": "CLIP_VISION"
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "ip_adaptor_sd15_pytorch_model.bin"
      ]
    },
    {
      "id": 14,
      "type": "LoadImage",
      "pos": [
        529.2491785312387,
        499.308898142746
      ],
      "size": [
        291.0731906494143,
        275.396897216797
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            34
          ],
          "shape": 3,
          "slot_index": 0,
          "label": "IMAGE"
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3,
          "label": "MASK"
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "https://bfs.esheep.com/bfs/aikobo-bfs/app/comfy/b5881c40e4ded2f7609ba4fec4a60f6467898756.png",
        "image"
      ]
    },
    {
      "id": 3,
      "type": "IPAdapterModelLoader",
      "pos": [
        523.2491785312387,
        290.30889814274684
      ],
      "size": {
        "0": 300,
        "1": 60
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            1
          ],
          "shape": 3,
          "slot_index": 0,
          "label": "IPADAPTER"
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "ip-adapter-plus-face_sd15.safetensors"
      ]
    },
    {
      "id": 22,
      "type": "CLIPSetLastLayer",
      "pos": [
        511.1231365931247,
        1103.4347960844427
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 35,
          "label": "clip"
        }
      ],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            36,
            37
          ],
          "shape": 3,
          "label": "CLIP",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPSetLastLayer"
      },
      "widgets_values": [
        -2
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        904.1231365931237,
        952.4347960844433
      ],
      "size": [
        347.27297399902363,
        151.9141505859377
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 36,
          "label": "clip"
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            25
          ],
          "shape": 3,
          "slot_index": 0,
          "label": "CONDITIONING"
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "1girlï¼Œlong hair"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 8,
      "type": "CLIPTextEncode",
      "pos": [
        906.1231365931237,
        1152.4347960844423
      ],
      "size": [
        336.77557399902366,
        140.0369505859378
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 37,
          "label": "clip"
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            9
          ],
          "shape": 3,
          "slot_index": 0,
          "label": "CONDITIONING"
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        ""
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 9,
      "type": "KSampler",
      "pos": [
        1307.1231365931237,
        941.4347960844433
      ],
      "size": {
        "0": 315,
        "1": 474
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 39,
          "label": "model"
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 25,
          "label": "positive"
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 9,
          "label": "negative"
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 26,
          "label": "latent_image"
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            11
          ],
          "shape": 3,
          "slot_index": 0,
          "label": "LATENT"
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        107,
        "increment",
        50,
        6,
        "euler_ancestral",
        "sgm_uniform",
        1
      ]
    },
    {
      "id": 11,
      "type": "VAEDecode",
      "pos": [
        1657.1231365931237,
        941.4347960844433
      ],
      "size": {
        "0": 140,
        "1": 50
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 11,
          "label": "samples"
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 29,
          "label": "vae"
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            13
          ],
          "shape": 3,
          "slot_index": 0,
          "label": "IMAGE"
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 10,
      "type": "EmptyLatentImage",
      "pos": [
        1310.1231365931237,
        1460.4347960844418
      ],
      "size": [
        304.36976035156295,
        120.00053715820354
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            26
          ],
          "shape": 3,
          "slot_index": 0,
          "label": "LATENT"
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        544,
        960,
        1
      ]
    },
    {
      "id": 12,
      "type": "SaveImage",
      "pos": [
        1872.1231365931237,
        948.4347960844433
      ],
      "size": [
        413.396864246369,
        635.6082024902348
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 13,
          "label": "images"
        }
      ],
      "properties": {},
      "widgets_values": [
        "IPAdapter"
      ]
    },
    {
      "id": 1,
      "type": "CheckpointLoaderSimple",
      "pos": [
        522.1231365931247,
        956.4347960844433
      ],
      "size": {
        "0": 300,
        "1": 100
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            4
          ],
          "shape": 3,
          "slot_index": 0,
          "label": "MODEL"
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            35
          ],
          "shape": 3,
          "slot_index": 1,
          "label": "CLIP"
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            29
          ],
          "shape": 3,
          "slot_index": 2,
          "label": "VAE"
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "683_3660_4305@fed2531e7e.safetensors"
      ]
    },
    {
      "id": 5,
      "type": "IPAdapterApply",
      "pos": [
        896.2491785312388,
        402.3088981427461
      ],
      "size": {
        "0": 210,
        "1": 258
      },
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 1,
          "label": "ipadapter"
        },
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 2,
          "label": "clip_vision"
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 34,
          "label": "image"
        },
        {
          "name": "model",
          "type": "MODEL",
          "link": 4,
          "label": "model"
        },
        {
          "name": "attn_mask",
          "type": "MASK",
          "link": null,
          "label": "attn_mask"
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            39
          ],
          "shape": 3,
          "slot_index": 0,
          "label": "MODEL"
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterApply"
      },
      "widgets_values": [
        0.35000000000000003,
        0.3,
        "original",
        0,
        1,
        false
      ]
    }
  ],
  "links": [
    [
      1,
      3,
      0,
      5,
      0,
      "IPADAPTER"
    ],
    [
      2,
      4,
      0,
      5,
      1,
      "CLIP_VISION"
    ],
    [
      4,
      1,
      0,
      5,
      3,
      "MODEL"
    ],
    [
      9,
      8,
      0,
      9,
      2,
      "CONDITIONING"
    ],
    [
      11,
      9,
      0,
      11,
      0,
      "LATENT"
    ],
    [
      13,
      11,
      0,
      12,
      0,
      "IMAGE"
    ],
    [
      25,
      7,
      0,
      9,
      1,
      "CONDITIONING"
    ],
    [
      26,
      10,
      0,
      9,
      3,
      "LATENT"
    ],
    [
      29,
      1,
      2,
      11,
      1,
      "VAE"
    ],
    [
      34,
      14,
      0,
      5,
      2,
      "IMAGE"
    ],
    [
      35,
      1,
      1,
      22,
      0,
      "CLIP"
    ],
    [
      36,
      22,
      0,
      7,
      0,
      "CLIP"
    ],
    [
      37,
      22,
      0,
      8,
      0,
      "CLIP"
    ],
    [
      39,
      5,
      0,
      9,
      0,
      "MODEL"
    ]
  ],
  "groups": [
    {
      "title": "Group",
      "bounding": [
        473,
        169,
        679,
        639
      ],
      "color": "#3f789e",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "Group",
      "bounding": [
        471,
        828,
        1886,
        797
      ],
      "color": "#3f789e",
      "font_size": 24,
      "locked": false
    }
  ],
  "config": {},
  "extra": {},
  "version": 0.4
}